{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SinghAnsh07/DataScience/blob/main/AI_Project_Fine_Tuned_VIT(Cancer_detection).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EI8YY23HZUmv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zILVTlQZFUl1"
      },
      "outputs": [],
      "source": [
        "# Extract to Colab's fast local storage\n",
        "!unzip -q \"/content/drive/MyDrive/BreaKHis_v1.zip\" -d /content/\n",
        "\n",
        "# Verify extraction\n",
        "!ls /content/BreaKHis_v1/histology_slides/breast\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0-WmFgIGbYx"
      },
      "outputs": [],
      "source": [
        "!pip install timm -q\n",
        "print(\"✓ Installation complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CbOnBVQG8Pd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score\n",
        "# from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "import timm\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "print(\"✓ All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maPzoHprHJKQ"
      },
      "outputs": [],
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(\"✓ GPU is ready for training!\")\n",
        "else:\n",
        "    print(\"⚠️ Warning: No GPU detected. Training will be slow.\")\n",
        "    print(\"Enable GPU: Runtime → Change runtime type → T4 GPU\")\n",
        "\n",
        "# Configuration\n",
        "data_root = '/content/BreaKHis_v1/histology_slides/breast'\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "learning_rate = 1e-4\n",
        "\n",
        "print(f\"\\nConfiguration:\")\n",
        "print(f\"  Dataset path: {data_root}\")\n",
        "print(f\"  Epochs: {epochs}\")\n",
        "print(f\"  Batch size: {batch_size}\")\n",
        "print(f\"  Learning rate: {learning_rate}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGm2gkrCHRgS"
      },
      "outputs": [],
      "source": [
        "data_root = '/content/BreaKHis_v1/histology_slides/breast'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj0U3Am0HTRd"
      },
      "outputs": [],
      "source": [
        "# Verify dataset structure\n",
        "print(\"Verifying dataset...\")\n",
        "print(f\"\\nChecking path: {data_root}\")\n",
        "\n",
        "benign_path = os.path.join(data_root, \"benign\")\n",
        "malignant_path = os.path.join(data_root, \"malignant\")\n",
        "\n",
        "if os.path.exists(benign_path) and os.path.exists(malignant_path):\n",
        "    print(\"✓ Dataset folders found!\")\n",
        "    print(f\"  - Benign folder: {benign_path}\")\n",
        "    print(f\"  - Malignant folder: {malignant_path}\")\n",
        "else:\n",
        "    print(\"❌ Dataset folders not found!\")\n",
        "    print(\"Check your data_root path\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJpP2N6OHluY"
      },
      "outputs": [],
      "source": [
        "# Dataset Class\n",
        "class BCDataset(Dataset):\n",
        "    def __init__(self, files, labels, transform=None):\n",
        "        self.files = files\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.files[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        return img, label\n",
        "\n",
        "print(\"✓ Dataset class created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5SbR3RqHpo_"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation for Training\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=30),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Data Transformation for Validation (no augmentation)\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"✓ Data transformations defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-YX6cyaHvz0"
      },
      "outputs": [],
      "source": [
        "def load_data(magnification='100X'):\n",
        "    \"\"\"Load and prepare BreakHis dataset\"\"\"\n",
        "    benign_path = os.path.join(data_root, \"benign\")\n",
        "    malignant_path = os.path.join(data_root, \"malignant\")\n",
        "\n",
        "    filenames, labels = [], []\n",
        "\n",
        "    # Load images\n",
        "    for path, label in [(benign_path, 0), (malignant_path, 1)]:\n",
        "        for root, _, files in os.walk(path):\n",
        "            if magnification in root:\n",
        "                for file in files:\n",
        "                    if file.lower().endswith('.png'):\n",
        "                        filenames.append(os.path.join(root, file))\n",
        "                        labels.append(label)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Dataset Loading Summary\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Magnification: {magnification}\")\n",
        "    print(f\"Total images: {len(filenames)}\")\n",
        "    print(f\"  - Benign: {labels.count(0)}\")\n",
        "    print(f\"  - Malignant: {labels.count(1)}\")\n",
        "\n",
        "    # Shuffle and split (80% train, 20% validation)\n",
        "    combined = list(zip(filenames, labels))\n",
        "    random.shuffle(combined)\n",
        "    filenames, labels = zip(*combined)\n",
        "\n",
        "    split_idx = int(0.8 * len(filenames))\n",
        "    train_files, val_files = filenames[:split_idx], filenames[split_idx:]\n",
        "    train_labels, val_labels = labels[:split_idx], labels[split_idx:]\n",
        "\n",
        "    print(f\"  - Training set: {len(train_files)}\")\n",
        "    print(f\"  - Validation set: {len(val_files)}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = BCDataset(train_files, train_labels, train_transform)\n",
        "    val_dataset = BCDataset(val_files, val_labels, val_transform)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                             shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
        "                           shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "print(\"✓ Data loading function created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ublpmuSIHx5r"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# BREAKHIS TRAINING - ALL MAGNIFICATIONS\n",
        "# Trains on 40X, 100X, 200X, and 400X\n",
        "# Target: 99% accuracy on each magnification\n",
        "# ============================================================\n",
        "\n",
        "# Install library\n",
        "!pip install timm -q\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "import timm\n",
        "from datetime import datetime\n",
        "\n",
        "# Set seeds\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\\n\")\n",
        "\n",
        "# Settings\n",
        "data_root = '/content/BreaKHis_v1/histology_slides/breast'\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "learning_rate = 3e-4\n",
        "\n",
        "# All magnifications to train on\n",
        "magnifications = ['40X', '100X', '200X', '400X']\n",
        "\n",
        "# Store results\n",
        "all_results = {}\n",
        "\n",
        "# ============================================================\n",
        "# DATASET CLASS\n",
        "# ============================================================\n",
        "class BCDataset(Dataset):\n",
        "    def __init__(self, files, labels, transform=None):\n",
        "        self.files = files\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.files[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "# ============================================================\n",
        "# DATA AUGMENTATION\n",
        "# ============================================================\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ============================================================\n",
        "# LOAD DATA FUNCTION\n",
        "# ============================================================\n",
        "def load_data(magnification):\n",
        "    benign_path = os.path.join(data_root, \"benign\")\n",
        "    malignant_path = os.path.join(data_root, \"malignant\")\n",
        "\n",
        "    filenames, labels = [], []\n",
        "    for path, label in [(benign_path, 0), (malignant_path, 1)]:\n",
        "        for root, _, files in os.walk(path):\n",
        "            if magnification in root:\n",
        "                for file in files:\n",
        "                    if file.lower().endswith('.png'):\n",
        "                        filenames.append(os.path.join(root, file))\n",
        "                        labels.append(label)\n",
        "\n",
        "    # Shuffle and split\n",
        "    combined = list(zip(filenames, labels))\n",
        "    random.shuffle(combined)\n",
        "    filenames, labels = zip(*combined)\n",
        "\n",
        "    split = int(0.8 * len(filenames))\n",
        "    train_files, val_files = filenames[:split], filenames[split:]\n",
        "    train_labels, val_labels = labels[:split], labels[split:]\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = BCDataset(train_files, train_labels, train_transform)\n",
        "    val_dataset = BCDataset(val_files, val_labels, val_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                             shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
        "                           shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader, len(filenames), labels.count(0), labels.count(1)\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING FUNCTION\n",
        "# ============================================================\n",
        "def train_magnification(magnification):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TRAINING: {magnification} MAGNIFICATION\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Load data\n",
        "    print(f\"Loading {magnification} dataset...\")\n",
        "    train_loader, val_loader, total, benign, malignant = load_data(magnification)\n",
        "\n",
        "    print(f\"Total images: {total}\")\n",
        "    print(f\"  Benign: {benign} | Malignant: {malignant}\")\n",
        "    print(f\"  Train batches: {len(train_loader)} | Val batches: {len(val_loader)}\\n\")\n",
        "\n",
        "    # Create model\n",
        "    print(f\"Creating ViT-Small model for {magnification}...\")\n",
        "    model = timm.create_model('vit_small_patch16_224', pretrained=True, num_classes=1)\n",
        "    model.to(device)\n",
        "\n",
        "    # Training setup\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
        "\n",
        "    # Training loop\n",
        "    print(f\"Starting training for {epochs} epochs...\\n\")\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = torch.sigmoid(model(images).squeeze())\n",
        "                predicted = (outputs > 0.5).float()\n",
        "                total_samples += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = correct / total_samples\n",
        "        avg_loss = train_loss / len(train_loader)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} | Accuracy: {accuracy*100:.2f}%\", end='')\n",
        "\n",
        "        # Save best model\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            model_path = f'/content/drive/MyDrive/best_breakhis_{magnification}.pth'\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(f\" ✓ BEST!\")\n",
        "        else:\n",
        "            print()\n",
        "\n",
        "    # Final evaluation\n",
        "    print(f\"\\n{'─'*70}\")\n",
        "    print(f\"FINAL EVALUATION - {magnification}\")\n",
        "    print(f\"{'─'*70}\")\n",
        "\n",
        "    model.load_state_dict(torch.load(f'/content/drive/MyDrive/best_breakhis_{magnification}.pth'))\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = torch.sigmoid(model(images).squeeze())\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    # Classification report\n",
        "    print(classification_report(all_labels, all_preds,\n",
        "                               target_names=['Benign', 'Malignant'],\n",
        "                               digits=4))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(f\"                Predicted\")\n",
        "    print(f\"              Benign  Malignant\")\n",
        "    print(f\"Actual Benign   {cm[0][0]:4d}      {cm[0][1]:4d}\")\n",
        "    print(f\"    Malignant   {cm[1][0]:4d}      {cm[1][1]:4d}\")\n",
        "\n",
        "    print(f\"\\n✓ {magnification} Training Complete!\")\n",
        "    print(f\"Best Accuracy: {best_accuracy*100:.2f}%\")\n",
        "    print(f\"Model saved: /content/drive/MyDrive/best_breakhis_{magnification}.pth\")\n",
        "\n",
        "    return best_accuracy, cm\n",
        "\n",
        "# ============================================================\n",
        "# TRAIN ALL MAGNIFICATIONS\n",
        "# ============================================================\n",
        "print(f\"\\n{'#'*70}\")\n",
        "print(f\"# BREAKHIS BREAST CANCER CLASSIFICATION - ALL MAGNIFICATIONS\")\n",
        "print(f\"# Training on: 40X, 100X, 200X, 400X\")\n",
        "print(f\"# Target: 99% accuracy on each magnification\")\n",
        "print(f\"{'#'*70}\")\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "for mag in magnifications:\n",
        "    accuracy, cm = train_magnification(mag)\n",
        "    all_results[mag] = {\n",
        "        'accuracy': accuracy,\n",
        "        'confusion_matrix': cm\n",
        "    }\n",
        "\n",
        "end_time = datetime.now()\n",
        "training_duration = end_time - start_time\n",
        "\n",
        "# ============================================================\n",
        "# FINAL SUMMARY REPORT\n",
        "# ============================================================\n",
        "print(f\"\\n\\n{'='*70}\")\n",
        "print(f\"COMPLETE TRAINING SUMMARY - ALL MAGNIFICATIONS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "print(f\"Training Duration: {training_duration}\\n\")\n",
        "\n",
        "print(f\"{'Magnification':<15} {'Accuracy':<15} {'Status'}\")\n",
        "print(f\"{'-'*70}\")\n",
        "\n",
        "for mag in magnifications:\n",
        "    accuracy = all_results[mag]['accuracy'] * 100\n",
        "    status = \"✓ EXCELLENT\" if accuracy >= 99 else \"✓ GOOD\" if accuracy >= 97 else \"⚠ NEEDS IMPROVEMENT\"\n",
        "    print(f\"{mag:<15} {accuracy:>6.2f}%{'':<8} {status}\")\n",
        "\n",
        "print(f\"\\n{'-'*70}\")\n",
        "\n",
        "# Average accuracy\n",
        "avg_accuracy = np.mean([all_results[mag]['accuracy'] * 100 for mag in magnifications])\n",
        "print(f\"{'Average':<15} {avg_accuracy:>6.2f}%\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"MODELS SAVED TO GOOGLE DRIVE:\")\n",
        "print(f\"{'='*70}\")\n",
        "for mag in magnifications:\n",
        "    print(f\"  • best_breakhis_{mag}.pth\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"✓ ALL MAGNIFICATIONS TRAINING COMPLETE!\")\n",
        "print(f\"Target (Gella 2024): 99.99% per magnification\")\n",
        "print(f\"Your Results: See table above\")\n",
        "print(f\"{'='*70}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}