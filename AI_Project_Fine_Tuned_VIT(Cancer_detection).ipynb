{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SinghAnsh07/DataScience/blob/main/AI_Project_Fine_Tuned_VIT(Cancer_detection).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI8YY23HZUmv",
        "outputId": "288cb7fe-026f-4cc4-f303-6638f13bb27b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zILVTlQZFUl1",
        "outputId": "64ac81f1-a6b9-4156-b345-e6c3024b3d5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace /content/BreaKHis_v1/histology_slides/breast/malignant/lobular_carcinoma.stat.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/count_files.sh? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/malignant/mucinous_carcinoma.stat.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/malignant/papillary_carcinoma.stat.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/malignant/ductal_carcinoma.stat.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/phyllodes_tumor.stat.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/process_db_stat.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/README.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/README_B.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/SOB/phyllodes_tumor/SOB_B_PT_14-22704/400X/SOB_B_PT-14-22704-400-030.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/malignant/ductal_carcinoma.stat.txt.SOB? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/SOB/phyllodes_tumor/SOB_B_PT_14-22704/400X/SOB_B_PT-14-22704-400-028.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/malignant/process_db_stat.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/tubular_adenoma.stat.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/adenosis.stat.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/SOB/phyllodes_tumor/SOB_B_PT_14-22704/400X/SOB_B_PT-14-22704-400-022.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/fibroadenoma.stat.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/SOB/phyllodes_tumor/SOB_B_PT_14-22704/400X/SOB_B_PT-14-22704-400-029.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/SOB/phyllodes_tumor/SOB_B_PT_14-22704/400X/SOB_B_PT-14-22704-400-020.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/SOB/phyllodes_tumor/SOB_B_PT_14-22704/400X/SOB_B_PT-14-22704-400-033.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/SOB/phyllodes_tumor/SOB_B_PT_14-22704/400X/SOB_B_PT-14-22704-400-013.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/SOB/phyllodes_tumor/SOB_B_PT_14-22704/400X/SOB_B_PT-14-22704-400-031.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/SOB/phyllodes_tumor/SOB_B_PT_14-22704/400X/SOB_B_PT-14-22704-400-032.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/SOB/phyllodes_tumor/SOB_B_PT_14-22704/400X/SOB_B_PT-14-22704-400-021.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/SOB/phyllodes_tumor/SOB_B_PT_14-22704/400X/SOB_B_PT-14-22704-400-024.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/SOB/phyllodes_tumor/SOB_B_PT_14-22704/400X/SOB_B_PT-14-22704-400-018.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/SOB/phyllodes_tumor/SOB_B_PT_14-22704/400X/SOB_B_PT-14-22704-400-015.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/SOB/phyllodes_tumor/SOB_B_PT_14-22704/400X/SOB_B_PT-14-22704-400-015.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace /content/BreaKHis_v1/histology_slides/breast/benign/SOB/phyllodes_tumor/SOB_B_PT_14-22704/400X/SOB_B_PT-14-22704-400-015.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: benign\tcount_files.sh\tmalignant  README.txt\n"
          ]
        }
      ],
      "source": [
        "# Extract to Colab's fast local storage\n",
        "!unzip -q \"/content/drive/MyDrive/BreaKHis_v1.zip\" -d /content/\n",
        "\n",
        "# Verify extraction\n",
        "!ls /content/BreaKHis_v1/histology_slides/breast\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "z0-WmFgIGbYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "665361a2-0190-4529-e1c1-f55c017ce03a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Installation complete!\n"
          ]
        }
      ],
      "source": [
        "!pip install timm -q\n",
        "print(\"✓ Installation complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "8CbOnBVQG8Pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca718df9-5c98-4379-bf14-96111af9f3f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "import timm\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "print(\"✓ All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "maPzoHprHJKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41cb5d69-3bcb-4887-c535-fe5793ebed27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: Tesla T4\n",
            "✓ GPU is ready for training!\n",
            "\n",
            "Configuration:\n",
            "  Dataset path: /content/BreaKHis_v1/histology_slides/breast\n",
            "  Epochs: 50\n",
            "  Batch size: 32\n",
            "  Learning rate: 0.0001\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(\"✓ GPU is ready for training!\")\n",
        "else:\n",
        "    print(\"⚠️ Warning: No GPU detected. Training will be slow.\")\n",
        "    print(\"Enable GPU: Runtime → Change runtime type → T4 GPU\")\n",
        "\n",
        "# Configuration\n",
        "data_root = '/content/BreaKHis_v1/histology_slides/breast'\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "learning_rate = 1e-4\n",
        "\n",
        "print(f\"\\nConfiguration:\")\n",
        "print(f\"  Dataset path: {data_root}\")\n",
        "print(f\"  Epochs: {epochs}\")\n",
        "print(f\"  Batch size: {batch_size}\")\n",
        "print(f\"  Learning rate: {learning_rate}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "tGm2gkrCHRgS"
      },
      "outputs": [],
      "source": [
        "data_root = '/content/BreaKHis_v1/histology_slides/breast'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "nj0U3Am0HTRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "712c84ce-6e28-49a9-bc32-1000f13a5cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying dataset...\n",
            "\n",
            "Checking path: /content/BreaKHis_v1/histology_slides/breast\n",
            "✓ Dataset folders found!\n",
            "  - Benign folder: /content/BreaKHis_v1/histology_slides/breast/benign\n",
            "  - Malignant folder: /content/BreaKHis_v1/histology_slides/breast/malignant\n"
          ]
        }
      ],
      "source": [
        "# Verify dataset structure\n",
        "print(\"Verifying dataset...\")\n",
        "print(f\"\\nChecking path: {data_root}\")\n",
        "\n",
        "benign_path = os.path.join(data_root, \"benign\")\n",
        "malignant_path = os.path.join(data_root, \"malignant\")\n",
        "\n",
        "if os.path.exists(benign_path) and os.path.exists(malignant_path):\n",
        "    print(\"✓ Dataset folders found!\")\n",
        "    print(f\"  - Benign folder: {benign_path}\")\n",
        "    print(f\"  - Malignant folder: {malignant_path}\")\n",
        "else:\n",
        "    print(\"❌ Dataset folders not found!\")\n",
        "    print(\"Check your data_root path\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "EJpP2N6OHluY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc34390-bc54-48e1-b46d-133c478adfc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Dataset class created!\n"
          ]
        }
      ],
      "source": [
        "# Dataset Class\n",
        "class BCDataset(Dataset):\n",
        "    def __init__(self, files, labels, transform=None):\n",
        "        self.files = files\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.files[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        return img, label\n",
        "\n",
        "print(\"✓ Dataset class created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "W5SbR3RqHpo_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e681146-7a2f-44c0-a9fa-7c75d76d299b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Data transformations defined!\n"
          ]
        }
      ],
      "source": [
        "# Data Augmentation for Training\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=30),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Data Transformation for Validation (no augmentation)\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"✓ Data transformations defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "2-YX6cyaHvz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94713075-dde0-4023-95f9-78c4467bcf5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Data loading function created!\n"
          ]
        }
      ],
      "source": [
        "def load_data(magnification='100X'):\n",
        "    \"\"\"Load and prepare BreakHis dataset\"\"\"\n",
        "    benign_path = os.path.join(data_root, \"benign\")\n",
        "    malignant_path = os.path.join(data_root, \"malignant\")\n",
        "\n",
        "    filenames, labels = [], []\n",
        "\n",
        "    # Load images\n",
        "    for path, label in [(benign_path, 0), (malignant_path, 1)]:\n",
        "        for root, _, files in os.walk(path):\n",
        "            if magnification in root:\n",
        "                for file in files:\n",
        "                    if file.lower().endswith('.png'):\n",
        "                        filenames.append(os.path.join(root, file))\n",
        "                        labels.append(label)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Dataset Loading Summary\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Magnification: {magnification}\")\n",
        "    print(f\"Total images: {len(filenames)}\")\n",
        "    print(f\"  - Benign: {labels.count(0)}\")\n",
        "    print(f\"  - Malignant: {labels.count(1)}\")\n",
        "\n",
        "    # Shuffle and split (80% train, 20% validation)\n",
        "    combined = list(zip(filenames, labels))\n",
        "    random.shuffle(combined)\n",
        "    filenames, labels = zip(*combined)\n",
        "\n",
        "    split_idx = int(0.8 * len(filenames))\n",
        "    train_files, val_files = filenames[:split_idx], filenames[split_idx:]\n",
        "    train_labels, val_labels = labels[:split_idx], labels[split_idx:]\n",
        "\n",
        "    print(f\"  - Training set: {len(train_files)}\")\n",
        "    print(f\"  - Validation set: {len(val_files)}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = BCDataset(train_files, train_labels, train_transform)\n",
        "    val_dataset = BCDataset(val_files, val_labels, val_transform)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                             shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
        "                           shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "print(\"✓ Data loading function created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "ublpmuSIHx5r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "605d6505-6dfd-47f1-e456-04801f445406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "\n",
            "\n",
            "######################################################################\n",
            "# BREAKHIS BREAST CANCER CLASSIFICATION - ALL MAGNIFICATIONS\n",
            "# Training on: 40X, 100X, 200X, 400X\n",
            "# Target: 99% accuracy on each magnification\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "TRAINING: 40X MAGNIFICATION\n",
            "======================================================================\n",
            "\n",
            "Loading 40X dataset...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2638435931.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmagnifications\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_magnification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     all_results[mag] = {\n\u001b[1;32m    246\u001b[0m         \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2638435931.py\u001b[0m in \u001b[0;36mtrain_magnification\u001b[0;34m(magnification)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loading {magnification} dataset...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmalignant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagnification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total images: {total}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2638435931.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(magnification)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "import timm\n",
        "from datetime import datetime\n",
        "\n",
        "# Set seeds\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\\n\")\n",
        "\n",
        "# Settings\n",
        "data_root = '/content/BreaKHis_v1/histology_slides/breast'\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "learning_rate = 3e-4\n",
        "\n",
        "# All magnifications to train on\n",
        "magnifications = ['40X', '100X', '200X', '400X']\n",
        "\n",
        "# Store results\n",
        "all_results = {}\n",
        "\n",
        "# ============================================================\n",
        "# DATASET CLASS\n",
        "# ============================================================\n",
        "class BCDataset(Dataset):\n",
        "    def __init__(self, files, labels, transform=None):\n",
        "        self.files = files\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.files[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "# ============================================================\n",
        "# DATA AUGMENTATION\n",
        "# ============================================================\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ============================================================\n",
        "# LOAD DATA FUNCTION\n",
        "# ============================================================\n",
        "def load_data(magnification):\n",
        "    benign_path = os.path.join(data_root, \"benign\")\n",
        "    malignant_path = os.path.join(data_root, \"malignant\")\n",
        "\n",
        "    filenames, labels = [], []\n",
        "    for path, label in [(benign_path, 0), (malignant_path, 1)]:\n",
        "        for root, _, files in os.walk(path):\n",
        "            if magnification in root:\n",
        "                for file in files:\n",
        "                    if file.lower().endswith('.png'):\n",
        "                        filenames.append(os.path.join(root, file))\n",
        "                        labels.append(label)\n",
        "\n",
        "    # If no images found for this magnification, return None for loaders\n",
        "    if not filenames:\n",
        "        print(f\"WARNING: No images found for magnification {magnification}. Returning empty loaders.\")\n",
        "        return None, None, 0, 0, 0 # Return None for loaders, and 0 for counts\n",
        "\n",
        "    # Shuffle and split\n",
        "    combined = list(zip(filenames, labels))\n",
        "    random.shuffle(combined)\n",
        "    filenames, labels = zip(*combined)\n",
        "\n",
        "    split = int(0.8 * len(filenames))\n",
        "    train_files, val_files = filenames[:split], filenames[split:]\n",
        "    train_labels, val_labels = labels[:split], labels[split:]\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = BCDataset(train_files, train_labels, train_transform)\n",
        "    val_dataset = BCDataset(val_files, val_labels, val_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                             shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
        "                           shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader, len(filenames), labels.count(0), labels.count(1)\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING FUNCTION\n",
        "# ============================================================\n",
        "def train_magnification(magnification):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TRAINING: {magnification} MAGNIFICATION\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Load data\n",
        "    print(f\"Loading {magnification} dataset...\")\n",
        "    train_loader, val_loader, total, benign, malignant = load_data(magnification)\n",
        "\n",
        "    if train_loader is None: # Check if load_data returned None, indicating no images found\n",
        "        print(f\"Skipping training for {magnification} due to no images found.\")\n",
        "        # Return 0 accuracy and None for confusion matrix if skipped\n",
        "        return 0.0, None\n",
        "\n",
        "    print(f\"Total images: {total}\")\n",
        "    print(f\"  Benign: {benign} | Malignant: {malignant}\")\n",
        "    print(f\"  Train batches: {len(train_loader)} | Val batches: {len(val_loader)}\\n\")\n",
        "\n",
        "    # Create model\n",
        "    print(f\"Creating ViT-Small model for {magnification}...\")\n",
        "    model = timm.create_model('vit_small_patch16_224', pretrained=True, num_classes=1)\n",
        "    model.to(device)\n",
        "\n",
        "    # Training setup\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
        "\n",
        "    # Training loop\n",
        "    print(f\"Starting training for {epochs} epochs...\\n\")\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for images, labels in tqdm(train_loader, desc=f\"{magnification} Epoch {epoch+1}/{epochs}\"):\n",
        "            images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = torch.sigmoid(model(images).squeeze())\n",
        "                predicted = (outputs > 0.5).float()\n",
        "                total_samples += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = correct / total_samples\n",
        "        avg_loss = train_loss / len(train_loader)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} | Accuracy: {accuracy*100:.2f}%\", end='')\n",
        "\n",
        "        # Save best model\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            model_path = f'/content/drive/MyDrive/best_breakhis_{magnification}.pth'\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(f\" \\u2713 BEST!\")\n",
        "        else:\n",
        "            print()\n",
        "\n",
        "    # Final evaluation\n",
        "    print(f\"\\n{'─'*70}\")\n",
        "    print(f\"FINAL EVALUATION - {magnification}\")\n",
        "    print(f\"{'─'*70}\")\n",
        "\n",
        "    # Check if a model was saved (i.e., best_accuracy > 0) to prevent loading an inexistent file\n",
        "    if best_accuracy > 0:\n",
        "        model.load_state_dict(torch.load(f'/content/drive/MyDrive/best_breakhis_{magnification}.pth'))\n",
        "        model.eval()\n",
        "\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images = images.to(device)\n",
        "                outputs = torch.sigmoid(model(images).squeeze())\n",
        "                predicted = (outputs > 0.5).float()\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.numpy())\n",
        "\n",
        "        # Classification report\n",
        "        print(classification_report(all_labels, all_preds,\n",
        "                                   target_names=['Benign', 'Malignant'],\n",
        "                                   digits=4))\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(all_labels, all_preds)\n",
        "        print(f\"\\nConfusion Matrix:\")\n",
        "        print(f\"                Predicted\")\n",
        "        print(f\"              Benign  Malignant\")\n",
        "        print(f\"Actual Benign   {cm[0][0]:4d}      {cm[0][1]:4d}\")\n",
        "        print(f\"    Malignant   {cm[1][0]:4d}      {cm[1][1]:4d}\")\n",
        "\n",
        "        print(f\"\\n\\u2713 {magnification} Training Complete!\")\n",
        "        print(f\"Best Accuracy: {best_accuracy*100:.2f}%\")\n",
        "        print(f\"Model saved: /content/drive/MyDrive/best_breakhis_{magnification}.pth\")\n",
        "\n",
        "        return best_accuracy, cm\n",
        "    else:\n",
        "        print(f\"\\n\\u26A0 No valid model was trained for {magnification} as no data was found or accuracy was 0.\")\n",
        "        return 0.0, None\n",
        "\n",
        "# ============================================================\n",
        "# TRAIN ALL MAGNIFICATIONS\n",
        "# ============================================================\n",
        "print(f\"\\n{'#'*70}\")\n",
        "print(f\"# BREAKHIS BREAST CANCER CLASSIFICATION - ALL MAGNIFICATIONS\")\n",
        "print(f\"# Training on: 40X, 100X, 200X, 400X\")\n",
        "print(f\"# Target: 99% accuracy on each magnification\")\n",
        "print(f\"{'#'*70}\")\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "for mag in magnifications:\n",
        "    accuracy, cm = train_magnification(mag)\n",
        "    if cm is not None:\n",
        "        all_results[mag] = {\n",
        "            'accuracy': accuracy,\n",
        "            'confusion_matrix': cm.tolist() # Convert numpy array to list for JSON compatibility\n",
        "        }\n",
        "    else:\n",
        "        all_results[mag] = {\n",
        "            'accuracy': 0.0, # Indicate skipped training with 0 accuracy\n",
        "            'confusion_matrix': 'Skipped - No data found'\n",
        "        }\n",
        "\n",
        "end_time = datetime.now()\n",
        "training_duration = end_time - start_time\n",
        "\n",
        "# ============================================================\n",
        "# FINAL SUMMARY REPORT\n",
        "# ============================================================\n",
        "print(f\"\\n\\n{'='*70}\")\n",
        "print(f\"COMPLETE TRAINING SUMMARY - ALL MAGNIFICATIONS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "print(f\"Training Duration: {training_duration}\\n\")\n",
        "\n",
        "print(f\"{'Magnification':<15} {'Accuracy':<15} {'Status'}\")\n",
        "print(f\"{'-'*70}\")\n",
        "\n",
        "for mag in magnifications:\n",
        "    if mag in all_results and all_results[mag]['confusion_matrix'] != 'Skipped - No data found':\n",
        "        accuracy = all_results[mag]['accuracy'] * 100\n",
        "        status = \"\\u2713 EXCELLENT\" if accuracy >= 99 else \"\\u2713 GOOD\" if accuracy >= 97 else \"\\u26A0 NEEDS IMPROVEMENT\"\n",
        "        print(f\"{mag:<15} {accuracy:>6.2f}%{'':<8} {status}\")\n",
        "    else:\n",
        "        print(f\"{mag:<15} {'SKIPPED':<15} {'\\u26A0 No Data'}\")\n",
        "\n",
        "print(f\"\\n{'-'*70}\")\n",
        "\n",
        "# Average accuracy (only for magnifications that were actually trained)\n",
        "actual_accuracies = [all_results[mag]['accuracy'] * 100 for mag in magnifications if all_results[mag]['confusion_matrix'] != 'Skipped - No data found']\n",
        "if actual_accuracies:\n",
        "    avg_accuracy = np.mean(actual_accuracies)\n",
        "    print(f\"{'Average':<15} {avg_accuracy:>6.2f}%\")\n",
        "else:\n",
        "    print(f\"{'Average':<15} {'N/A':>6s}%\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"MODELS SAVED TO GOOGLE DRIVE:\")\n",
        "print(f\"{'='*70}\")\n",
        "for mag in magnifications:\n",
        "    if mag in all_results and all_results[mag]['confusion_matrix'] != 'Skipped - No data found':\n",
        "        print(f\"  • best_breakhis_{mag}.pth\")\n",
        "    else:\n",
        "        print(f\"  • No model saved for {mag} (skipped)\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"\\u2713 ALL MAGNIFICATIONS TRAINING COMPLETE!\")\n",
        "print(f\"Target (Gella 2024): 99.99% per magnification\")\n",
        "print(f\"Your Results: See table above\")\n",
        "print(f\"{'='*70}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e1c5f2f"
      },
      "source": [
        "print(\"Checking contents of /content/drive/MyDrive/:\")\n",
        "!ls -F /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2ab1edf"
      },
      "source": [
        "Please make sure that `BreaKHis_v1.zip` is listed in the output above. If it's not, please upload the file to your Google Drive and then re-run the relevant cells starting from the extraction step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cc715f3"
      },
      "source": [
        "# Task\n",
        "Train a breast cancer classification model for all magnifications (40X, 100X, 200X, 400X), saving the best performing model for each magnification to Google Drive, then verify the saved models, and finally summarize the training results and model locations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f1439fa"
      },
      "source": [
        "## Execute Model Training\n",
        "\n",
        "### Subtask:\n",
        "Run the cell that trains the breast cancer classification model across all specified magnifications (40X, 100X, 200X, 400X). This cell will handle data loading, model creation, training, validation, and saving the best model for each magnification to Google Drive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6de2801"
      },
      "source": [
        "**Reasoning**:\n",
        "The user wants to execute the code cell that starts with the comment '# ============================================================' and contains the full training loop for all magnifications. I have identified this as cell `ublpmuSIHx5r` in the provided notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c982c0bd"
      },
      "source": [
        "# ============================================================\n",
        "# BREAKHIS TRAINING - ALL MAGNIFICATIONS\n",
        "# Trains on 40X, 100X, 200X, and 400X\n",
        "# Target: 99% accuracy on each magnification\n",
        "# ============================================================\n",
        "\n",
        "# Install library\n",
        "!pip install timm -q\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "import timm\n",
        "from datetime import datetime\n",
        "\n",
        "# Set seeds\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\\n\")\n",
        "\n",
        "# Settings\n",
        "data_root = '/content/BreaKHis_v1/histology_slides/breast'\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "learning_rate = 3e-4\n",
        "\n",
        "# All magnifications to train on\n",
        "magnifications = ['40X', '100X', '200X', '400X']\n",
        "\n",
        "# Store results\n",
        "all_results = {}\n",
        "\n",
        "# ============================================================\n",
        "# DATASET CLASS\n",
        "# ============================================================\n",
        "class BCDataset(Dataset):\n",
        "    def __init__(self, files, labels, transform=None):\n",
        "        self.files = files\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.files[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "# ============================================================\n",
        "# DATA AUGMENTATION\n",
        "# ============================================================\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ============================================================\n",
        "# LOAD DATA FUNCTION\n",
        "# ============================================================\n",
        "def load_data(magnification):\n",
        "    benign_path = os.path.join(data_root, \"benign\")\n",
        "    malignant_path = os.path.join(data_root, \"malignant\")\n",
        "\n",
        "    filenames, labels = [], []\n",
        "    for path, label in [(benign_path, 0), (malignant_path, 1)]:\n",
        "        for root, _, files in os.walk(path):\n",
        "            if magnification in root:\n",
        "                for file in files:\n",
        "                    if file.lower().endswith('.png'):\n",
        "                        filenames.append(os.path.join(root, file))\n",
        "                        labels.append(label)\n",
        "\n",
        "    # Shuffle and split\n",
        "    combined = list(zip(filenames, labels))\n",
        "    random.shuffle(combined)\n",
        "    filenames, labels = zip(*combined)\n",
        "\n",
        "    split = int(0.8 * len(filenames))\n",
        "    train_files, val_files = filenames[:split], filenames[split:]\n",
        "    train_labels, val_labels = labels[:split], labels[split:]\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = BCDataset(train_files, train_labels, train_transform)\n",
        "    val_dataset = BCDataset(val_files, val_labels, val_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                             shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
        "                           shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader, len(filenames), labels.count(0), labels.count(1)\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING FUNCTION\n",
        "# ============================================================\n",
        "def train_magnification(magnification):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TRAINING: {magnification} MAGNIFICATION\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Load data\n",
        "    print(f\"Loading {magnification} dataset...\")\n",
        "    train_loader, val_loader, total, benign, malignant = load_data(magnification)\n",
        "\n",
        "    print(f\"Total images: {total}\")\n",
        "    print(f\"  Benign: {benign} | Malignant: {malignant}\")\n",
        "    print(f\"  Train batches: {len(train_loader)} | Val batches: {len(val_loader)}\\n\")\n",
        "\n",
        "    # Create model\n",
        "    print(f\"Creating ViT-Small model for {magnification}...\")\n",
        "    model = timm.create_model('vit_small_patch16_224', pretrained=True, num_classes=1)\n",
        "    model.to(device)\n",
        "\n",
        "    # Training setup\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
        "\n",
        "    # Training loop\n",
        "    print(f\"Starting training for {epochs} epochs...\\n\")\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for images, labels in tqdm(train_loader, desc=f\"{magnification} Epoch {epoch+1}/{epochs}\"):\n",
        "            images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = torch.sigmoid(model(images).squeeze())\n",
        "                predicted = (outputs > 0.5).float()\n",
        "                total_samples += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = correct / total_samples\n",
        "        avg_loss = train_loss / len(train_loader)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} | Accuracy: {accuracy*100:.2f}%\", end='')\n",
        "\n",
        "        # Save best model\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            model_path = f'/content/drive/MyDrive/best_breakhis_{magnification}.pth'\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(f\" \\u2713 BEST!\")\n",
        "        else:\n",
        "            print()\n",
        "\n",
        "    # Final evaluation\n",
        "    print(f\"\\n{'─'*70}\")\n",
        "    print(f\"FINAL EVALUATION - {magnification}\")\n",
        "    print(f\"{'─'*70}\")\n",
        "\n",
        "    model.load_state_dict(torch.load(f'/content/drive/MyDrive/best_breakhis_{magnification}.pth'))\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = torch.sigmoid(model(images).squeeze())\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    # Classification report\n",
        "    print(classification_report(all_labels, all_preds,\n",
        "                               target_names=['Benign', 'Malignant'],\n",
        "                               digits=4))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(f\"                Predicted\")\n",
        "    print(f\"              Benign  Malignant\")\n",
        "    print(f\"Actual Benign   {cm[0][0]:4d}      {cm[0][1]:4d}\")\n",
        "    print(f\"    Malignant   {cm[1][0]:4d}      {cm[1][1]:4d}\")\n",
        "\n",
        "    print(f\"\\n\\u2713 {magnification} Training Complete!\")\n",
        "    print(f\"Best Accuracy: {best_accuracy*100:.2f}%\")\n",
        "    print(f\"Model saved: /content/drive/MyDrive/best_breakhis_{magnification}.pth\")\n",
        "\n",
        "    return best_accuracy, cm\n",
        "\n",
        "# ============================================================\n",
        "# TRAIN ALL MAGNIFICATIONS\n",
        "# ============================================================\n",
        "print(f\"\\n{'#'*70}\")\n",
        "print(f\"# BREAKHIS BREAST CANCER CLASSIFICATION - ALL MAGNIFICATIONS\")\n",
        "print(f\"# Training on: 40X, 100X, 200X, 400X\")\n",
        "print(f\"# Target: 99% accuracy on each magnification\")\n",
        "print(f\"{'#'*70}\")\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "for mag in magnifications:\n",
        "    accuracy, cm = train_magnification(mag)\n",
        "    all_results[mag] = {\n",
        "        'accuracy': accuracy,\n",
        "        'confusion_matrix': cm\n",
        "    }\n",
        "\n",
        "end_time = datetime.now()\n",
        "training_duration = end_time - start_time\n",
        "\n",
        "# ============================================================\n",
        "# FINAL SUMMARY REPORT\n",
        "# ============================================================\n",
        "print(f\"\\n\\n{'='*70}\")\n",
        "print(f\"COMPLETE TRAINING SUMMARY - ALL MAGNIFICATIONS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "print(f\"Training Duration: {training_duration}\\n\")\n",
        "\n",
        "print(f\"{'Magnification':<15} {'Accuracy':<15} {'Status'}\")\n",
        "print(f\"{'-'*70}\")\n",
        "\n",
        "for mag in magnifications:\n",
        "    accuracy = all_results[mag]['accuracy'] * 100\n",
        "    status = \"\\u2713 EXCELLENT\" if accuracy >= 99 else \"\\u2713 GOOD\" if accuracy >= 97 else \"\\u26A0 NEEDS IMPROVEMENT\"\n",
        "    print(f\"{mag:<15} {accuracy:>6.2f}%{'':<8} {status}\")\n",
        "\n",
        "print(f\"\\n{'-'*70}\")\n",
        "\n",
        "# Average accuracy\n",
        "avg_accuracy = np.mean([all_results[mag]['accuracy'] * 100 for mag in magnifications])\n",
        "print(f\"{'Average':<15} {avg_accuracy:>6.2f}%\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"MODELS SAVED TO GOOGLE DRIVE:\")\n",
        "print(f\"{'='*70}\")\n",
        "for mag in magnifications:\n",
        "    print(f\"  • best_breakhis_{mag}.pth\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"\\u2713 ALL MAGNIFICATIONS TRAINING COMPLETE!\")\n",
        "print(f\"Target (Gella 2024): 99.99% per magnification\")\n",
        "print(f\"Your Results: See table above\")\n",
        "print(f\"{'='*70}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}