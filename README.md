ðŸ§¬ Breast Cancer Histopathology Classification (BreaKHis)

This project implements Vision Transformer (ViT-Small) models to classify benign vs malignant breast cancer histopathology images using the BreaKHis dataset, trained independently across four magnification levels (40Xâ€“400X).
The goal was to evaluate the robustness of ViT-based models across varying microscopic resolutions and achieve high diagnostic accuracy.

ðŸš€ Features

Multi-magnification training: 40X, 100X, 200X, 400X
Vision Transformer (ViT-Small) architecture
Data augmentation for improved generalization
Cosine learning rate scheduling
Independent model per magnification
Robust handling of missing data
Google Colab + GPU (CUDA) compatible
Models saved automatically to Google Drive

### Note
The notebook is provided as source code only.
Training outputs and models are generated during execution.


======================================================================
COMPLETE TRAINING SUMMARY - ALL MAGNIFICATIONS
======================================================================

Training Duration: 3:46:55

Magnification   Accuracy    Status
--------------------------------------------------
40X             99.50%      âœ“ EXCELLENT
100X            98.80%      âœ“ GOOD
200X            99.50%      âœ“ EXCELLENT
400X            99.18%      âœ“ EXCELLENT

--------------------------------------------------
Average         99.24%
======================================================================

MODELS SAVED TO GOOGLE DRIVE:
  â€¢ best_breakhis_40X.pth
  â€¢ best_breakhis_100X.pth
  â€¢ best_breakhis_200X.pth
  â€¢ best_breakhis_400X.pth

======================================================================
âœ“ ALL MAGNIFICATIONS TRAINING COMPLETE!
Target (Gella 2024): 99.99% per magnification
Your Results: See table above
======================================================================
